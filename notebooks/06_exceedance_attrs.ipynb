{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dbee3f-f300-4868-9249-f434e3800a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jason Chiappa 2025\n",
    "# Calculates the following attributes based on each event's exceedance footprint:\n",
    "# Approximate major axis length of the exceedance swath associated with the point of max exceedance and it's forward azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4f60c-8422-4064-aa1e-5870c1b859b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "import pyproj\n",
    "geodesicp = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10455da-df55-466a-9651-62601218ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#### PLEASE MODIFY AS NEEDED ####\n",
    "##############################################################################################\n",
    "\n",
    "# Separation distance between simultaneous events\n",
    "sep_dist = 250\n",
    "# sep_dist = 100\n",
    "\n",
    "# IMPORTANT!!!\n",
    "# True if resuming (or adding additional data to append to dataset), false if starting from beginning.\n",
    "# Failing to change to True will overwrite all previous data and recalculate the parameters.\n",
    "resume = False\n",
    "\n",
    "# TIME RANGE for this run (YYYY-MM-DD HH:MM:SS) [change if resuming]\n",
    "start_time = '2002-01-01 00:00:00'\n",
    "end_time = '2024-12-31 23:00:00'\n",
    "\n",
    "# Main data directory (containing ere_database_prelim_[sep_dist].csv)\n",
    "datadir = 'C:/Users/jchiappa/OneDrive - University of Oklahoma/ERE_analysis/v2/data/'\n",
    "\n",
    "# Accumulation map array directory\n",
    "arr_dir = 'E:/Research/EREs/data/array_output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3dc15e-dac5-40a0-8341-1e22aa9b9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#### Leave the stuff below ####\n",
    "##############################################################################################\n",
    "\n",
    "# exceedance point list directory\n",
    "path = arr_dir+str(sep_dist)+'km/exceedpts/10yr/'\n",
    "\n",
    "# preliminary database file name\n",
    "dbfname = 'ere_database_qcflagged_'+str(sep_dist)+'km.csv'\n",
    "\n",
    "# output database file name\n",
    "outputfname = 'ere_database_exattrs_'+str(sep_dist)+'km.csv'\n",
    "\n",
    "# list of all times (by hour) in selected time range\n",
    "times = pd.Series(pd.date_range(start_time,end_time, freq='h')).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c003c-6cff-4c54-8920-9d0fe3edeb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# degree longitude to distance (km)\n",
    "def dlon_km(event_lat):\n",
    "    coord1 = (event_lat,0)\n",
    "    coord2 = (event_lat,1)\n",
    "    return(geodesic(coord1,coord2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd6bf0-e138-439f-95c9-d4ba0ad201b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of attribute names\n",
    "attrs = ['exceed_length','exceed_azimuth']\n",
    "\n",
    "data = {}\n",
    "for attr in attrs:\n",
    "    data[attr] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869782c-9f90-432c-8a52-62eb4f95143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume:\n",
    "    # load existing and save parameters to list to be added to\n",
    "    df0 = pd.read_csv(datadir+outputfname)\n",
    "    df0['event_time'] = pd.to_datetime(df0['event_time'], format=\"%Y%m%d%H\")\n",
    "    # save parameters for events before run period\n",
    "    df0 = df0[df0.event_time < times[0]]\n",
    "    \n",
    "    for attr in attrs:\n",
    "        data[attr] += df0[attr].to_list()\n",
    "\n",
    "# event database\n",
    "df = pd.read_csv(datadir+dbfname)\n",
    "df['event_time'] = pd.to_datetime(df['event_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# dataframe with events to analyze\n",
    "df1 = df[(df.event_time >= times[0]) & (df.event_time <= times[-1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eea97b-a873-4d89-baa9-f4225e6ec31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lists from dataframe\n",
    "events = df1.event.to_list()\n",
    "event_lats = df1.lat.to_list()\n",
    "event_lons = df1.lon.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05465fd5-41a1-4404-9174-40248966b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups all contiguous points exceeding a threshold surounding the point of max exceedance\n",
    "# input event id, search radius in pixels (4km each)\n",
    "def group(event,searchradius=1):\n",
    "    i = events.index(event)\n",
    "\n",
    "    maxlat = event_lats[i]\n",
    "    maxlon = event_lons[i]\n",
    "    \n",
    "    dlon = dlon_km(maxlat)\n",
    "    dlat = 111\n",
    "    \n",
    "    # lat/lon box radius for gathering adjacent/surrounding searchradius grid points only\n",
    "    latrad = (searchradius*4/dlat) + (2/dlat)\n",
    "    lonrad = (searchradius*4/dlon) + (2/dlon)\n",
    "\n",
    "    expts = np.load(path+str(event).zfill(5)+'.npy')\n",
    "\n",
    "    latexceed = expts[:,0]\n",
    "    lonexceed = expts[:,1]\n",
    "    \n",
    "    max_indexs = np.where((latexceed>maxlat-4/dlat/2) & (latexceed<maxlat+4/dlat/2) &\n",
    "                         (lonexceed>maxlon-4/dlon/2) & (lonexceed<maxlon+4/dlon/2))[0]\n",
    "    \n",
    "\n",
    "    max_index = max_indexs[0]\n",
    "\n",
    "    grouplats = [latexceed[max_index]]\n",
    "    grouplons = [lonexceed[max_index]]\n",
    "\n",
    "    latexceed = np.delete(latexceed,max_index)\n",
    "    lonexceed = np.delete(lonexceed,max_index)\n",
    "\n",
    "    grouplen = [0,len(grouplats)]\n",
    "\n",
    "    while grouplen[-1] > grouplen[-2]:\n",
    "        for ptidx in range(grouplen[-2],grouplen[-1]):\n",
    "            ptlat = grouplats[ptidx]\n",
    "            ptlon = grouplons[ptidx]\n",
    "            nearidxs = np.where((latexceed>ptlat-latrad) & (latexceed<ptlat+latrad) &\n",
    "                                (lonexceed>ptlon-lonrad) & (lonexceed<ptlon+lonrad))[0]\n",
    "            if len(nearidxs) > 0:\n",
    "                for nidx in nearidxs:\n",
    "                    grouplats.append(latexceed[nidx])\n",
    "                    grouplons.append(lonexceed[nidx])\n",
    "            latexceed = np.delete(latexceed,nearidxs)\n",
    "            lonexceed = np.delete(lonexceed,nearidxs)\n",
    "\n",
    "        grouplen.append(len(grouplats))\n",
    "\n",
    "        return(np.array(grouplats),np.array(grouplons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478e19f-f9d8-4378-b988-65e42c8b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exceed_attrs(event):\n",
    "\n",
    "    grouplats,grouplons = group(event)\n",
    "\n",
    "    if len(grouplats) == 0:\n",
    "        length,lat1,lon1,lat2,lon2,fwd_azimuth = -999,-999,-999,-999,-999,-999\n",
    "\n",
    "    else:\n",
    "        lat_argmin = np.nanargmin(grouplats)\n",
    "        lat_argmax = np.nanargmax(grouplats)\n",
    "        lon_argmin = np.nanargmin(grouplons)\n",
    "        lon_argmax = np.nanargmax(grouplons)\n",
    "\n",
    "        lat_minpt = (grouplats[lat_argmin],grouplons[lat_argmin])\n",
    "        lat_maxpt = (grouplats[lat_argmax],grouplons[lat_argmax])\n",
    "        lon_minpt = (grouplats[lon_argmin],grouplons[lon_argmin])\n",
    "        lon_maxpt = (grouplats[lon_argmax],grouplons[lon_argmax])\n",
    "\n",
    "        lat_dist = geodesic(lat_minpt,lat_maxpt).km\n",
    "        lon_dist = geodesic(lon_minpt,lon_maxpt).km\n",
    "\n",
    "        imax = [lat_dist,lon_dist].index(max([lat_dist,lon_dist]))\n",
    "        length = [lat_dist,lon_dist][imax]\n",
    "        lat1 = [lat_minpt[0],lon_minpt[0]][imax]\n",
    "        lon1 = [lat_minpt[1],lon_minpt[1]][imax]\n",
    "        lat2 = [lat_maxpt[0],lon_maxpt[0]][imax]\n",
    "        lon2 = [lat_maxpt[1],lon_maxpt[1]][imax]\n",
    "\n",
    "        fwd_azimuth,back_azimuth,distance = geodesicp.inv(lon1, lat1, lon2, lat2)\n",
    "\n",
    "        if fwd_azimuth < 0:\n",
    "            fwd_azimuth = fwd_azimuth+180\n",
    "            \n",
    "    if length==0.0:\n",
    "        fwd_azimuth = -999\n",
    "            \n",
    "    return(length,fwd_azimuth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b84666-1832-49d6-ade3-797f402f71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform calculations for each event\n",
    "for event in events:\n",
    "    # calculate exceedance swath length and azimuth\n",
    "    length,fwd_azimuth = exceed_attrs(event)\n",
    "    data['exceed_length'].append(length)\n",
    "    data['exceed_azimuth'].append(fwd_azimuth)\n",
    "    \n",
    "    print(str(event)+'/'+str(events[-1]),end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6ed98f-e2c2-4c4e-b88e-22de515c410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attrs:\n",
    "    df[attr] = data[attr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256dc04-32c3-4ae6-854d-7a6ee303851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(datadir+outputfname,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
