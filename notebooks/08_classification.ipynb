{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004698fc-9487-48cd-8c21-c771ec77e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jason Chiappa 2025\n",
    "# Applies conditions for classification as tropcial cyclone, isolated, MCS/synoptic, and nocturnal\n",
    "# Also adds diurnal cycle attributes and the following attributes based on each event's 1 mm/hr precipitation feature:\n",
    "# Maximum major axis length, number of consicutive hours with length (km) > MCS/isolated threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c0795-9e09-43bf-b691-cb55659a9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sun import sun\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import groupby\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa00208-f44a-4f4f-acf2-d9d6fb006eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#### PLEASE MODIFY AS NEEDED ####\n",
    "##############################################################################################\n",
    "\n",
    "# Separation distance between simultaneous events\n",
    "sep_dist = 250\n",
    "# sep_dist = 100\n",
    "\n",
    "# Main data directory (containing ere_database csv files)\n",
    "datadir = 'C:/Users/jchiappa/OneDrive - University of Oklahoma/ERE_analysis/v2/data/'\n",
    "\n",
    "# ibtracs file name\n",
    "ibtracsfname = 'ibtracs.since1980.list.v04r01.csv'\n",
    "\n",
    "# Will run for entire dataset (regardless of resuming) due to short runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894007a-d8be-4af1-9006-24f8abc2256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input database file name\n",
    "dbfname = 'ere_database_exattrs_'+str(sep_dist)+'km.csv'\n",
    "\n",
    "# input pf database file name\n",
    "pfdbfname = 'ere_database_pfs_'+str(sep_dist)+'km.csv'\n",
    "\n",
    "# output database file name\n",
    "outputfname = 'ere_database_classflagged_'+str(sep_dist)+'km.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f98d7b4-765a-425f-9722-71864d8be88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tropical cyclone center within tc_latlondist degrees (lat/lon) of point of max exceedance \n",
    "# and within tc_timerange hours of peak accumulation hour classified as TC\n",
    "tc_latlondist = 3\n",
    "tc_timerange = 24\n",
    "\n",
    "# Isolated classified as having maximum PF length < iso_length (km)\n",
    "iso_length = 200\n",
    "\n",
    "# MCS/synoptic classified as having PF length >= mcs_length (km) for at least mcs_time consecutive hours\n",
    "mcs_length = 200\n",
    "mcs_time = 4\n",
    "\n",
    "# Nocturnal classified as having peak accumulation hour at night and/or \n",
    "# having at least this fraction of nighttime hours to the total event duration\n",
    "night_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60f22b-f192-4e8b-b416-a5105bcb3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open main ERE database\n",
    "df = pd.read_csv(datadir+dbfname)\n",
    "\n",
    "df['event_time'] = pd.to_datetime(df['event_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df['start_time'] = pd.to_datetime(df['start_time'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df['accum_time'] = pd.to_datetime(df['accum_time'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b200e34-29e7-4d26-8875-3ebd1721f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = df.event.to_list()\n",
    "event_times = df.event_time.to_list()\n",
    "start_times = df.start_time.to_list()\n",
    "end_times = df.accum_time.to_list()\n",
    "event_lats = df.lat.to_list()\n",
    "event_lons = df.lon.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175bbf9b-9ac2-442e-add1-0a1820c2843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of hours between sunset and sunrise (location/date-dependent)\n",
    "night_hours = []\n",
    "# and flag whether peak accumulation hour is at night\n",
    "night_flags = []\n",
    "\n",
    "for i in range(len(events)):\n",
    "    event_time = event_times[i]\n",
    "    start_time = start_times[i]\n",
    "    end_time = end_times[i]\n",
    "    event_lat = event_lats[i]\n",
    "    event_lon = event_lons[i]\n",
    "    \n",
    "    try:\n",
    "        s = sun(lat=event_lat,long=event_lon)\n",
    "        sset = s.sunset(datetime(event_time.year, event_time.month, event_time.day))\n",
    "    except:\n",
    "        s = sun(lat=event_lat,long=event_lon+360)\n",
    "        sset = s.sunset(datetime(event_time.year, event_time.month, event_time.day))\n",
    "\n",
    "    try:\n",
    "        s = sun(lat=event_lat,long=event_lon)\n",
    "        srise = s.sunrise(datetime(event_time.year, event_time.month, event_time.day))\n",
    "    except:\n",
    "        s = sun(lat=event_lat,long=event_lon+360)\n",
    "        srise = s.sunrise(datetime(event_time.year, event_time.month, event_time.day))\n",
    "        \n",
    "    # check if event hour is at night\n",
    "    h = event_time.hour\n",
    "    \n",
    "    if sset.hour>12:\n",
    "        if ((h>sset.hour) | (h<srise.hour)):\n",
    "            night_flags.append(1)\n",
    "        else:\n",
    "            night_flags.append(0)\n",
    "    else:\n",
    "        if ((h>sset.hour) & (h<srise.hour)):\n",
    "            night_flags.append(1)\n",
    "        else:\n",
    "            night_flags.append(0)\n",
    "    \n",
    "    # count FULL hours between sunset and sunrise\n",
    "    # nighttime hours are considered fully within the bounds of sunset-sunrise\n",
    "    \n",
    "    event_hours = pd.date_range(start_time,end_time-pd.Timedelta(1,unit='h'),freq='h').hour.to_list()\n",
    "    \n",
    "    if sset.hour>12:\n",
    "        total_night_hours = sum((h>sset.hour) | (h<srise.hour) for h in event_hours)\n",
    "    else:\n",
    "        total_night_hours = sum((h>sset.hour) & (h<srise.hour) for h in event_hours)\n",
    "        \n",
    "    night_hours.append(total_night_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15609c52-7ce6-4c07-b656-00a29e4dcc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add diurnal attributes\n",
    "df2 = df.copy()\n",
    "df2['night_flag'] = night_flags\n",
    "df2['night_hours'] = night_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7d2c0-e0da-47e8-b8e0-0a96e57d840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create nocturnal flags\n",
    "noct_flags = []\n",
    "\n",
    "for event in df2.event:\n",
    "    event_df = df2[df2.event == event]\n",
    "    \n",
    "    if ((event_df.night_hours.to_list()[0]/event_df.duration.to_list()[0] >= night_ratio) | \n",
    "        (event_df.night_flag.to_list()[0] == 1)):\n",
    "        noct_flags.append(1)\n",
    "    else:\n",
    "        noct_flags.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657cff9-eba1-432a-a338-b577369f7c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8db20e-a55c-4d05-a5e6-a9889c535404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open tropical cyclone data\n",
    "tc = pd.read_csv(datadir+ibtracsfname, header=0, na_filter=False, low_memory=False)\n",
    "tc = tc.drop(0, axis=0)\n",
    "\n",
    "#Contert 'ISO_time' to datetime\n",
    "tc['ISO_TIME'] = pd.to_datetime(tc['ISO_TIME'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "tc['LAT'] = pd.to_numeric(tc['LAT'])\n",
    "tc['LON'] = pd.to_numeric(tc['LON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e022544-3500-4b3d-b1f3-1c4575e98fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tc classifications\n",
    "tc_flags = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    event = df.iloc[i]\n",
    "    \n",
    "    start = event.event_time - timedelta(hours=tc_timerange)\n",
    "    end = event.event_time + timedelta(hours=tc_timerange)\n",
    "    lat = event.lat\n",
    "    lon = event.lon\n",
    "    \n",
    "    tc_hits = tc[(tc.ISO_TIME>=start) & (tc.ISO_TIME<=end) & (tc.LAT>=lat-tc_latlondist) & (tc.LAT<=lat+tc_latlondist) & \n",
    "             (tc.LON>=lon-tc_latlondist) & (tc.LON<=lon+tc_latlondist)]\n",
    "\n",
    "    if len(tc_hits) > 0:\n",
    "        tc_flags.append(1)\n",
    "    else:\n",
    "        tc_flags.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250b293-3380-406f-9f3f-6c489c62908c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc259803-5c0d-42bb-a9a9-ea74f019920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open PF database\n",
    "df_pfs = pd.read_csv(datadir+pfdbfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f800fb-a3c4-4754-a10c-8b8846214598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pf attributes\n",
    "max_lengths = []\n",
    "max_consecutive_durations = []\n",
    "hour_counts = []\n",
    "azimuths = []\n",
    "# hours greater than iso length\n",
    "\n",
    "for event in events:\n",
    "    event_df = df_pfs[df_pfs.event == event]\n",
    "    max_lengths.append(event_df.pf_length.max())\n",
    "    \n",
    "    lexceed_df = event_df[event_df.pf_length > mcs_length]\n",
    "    \n",
    "    hr_count = len(lexceed_df)\n",
    "    hour_counts.append(hr_count)\n",
    "    \n",
    "    if hr_count == 1:\n",
    "        azimuths.append(lexceed_df.azimuth.mean())\n",
    "        max_consecutive_durations.append(1)\n",
    "\n",
    "    elif hr_count > 1:\n",
    "        azmax = lexceed_df.azimuth[lexceed_df.idxmax(axis=0)['pf_length']]\n",
    "        azimuths.append(azmax)\n",
    "        \n",
    "        # find maximum number of consecutive hours exceeding threshold\n",
    "        dlist = list(np.diff(lexceed_df.index))\n",
    "        iterlist = [(k, sum(1 for i in g)) for k,g in groupby(dlist)]\n",
    "        ilist2 = [b for b in iterlist if b[0]==1]\n",
    "        if len(ilist2) > 0:\n",
    "            ilist3 = [c[1] for c in ilist2]\n",
    "            maxdur = max(ilist3)+1\n",
    "            max_consecutive_durations.append(maxdur)\n",
    "        else:\n",
    "            max_consecutive_durations.append(1)\n",
    "                        \n",
    "    else:\n",
    "        azimuths.append(-999)\n",
    "        max_consecutive_durations.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e213f3c-080e-4114-8619-6e59555c3a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pf attributes\n",
    "df2['max_pflength'] = max_lengths\n",
    "# df2['length_hours'] = hour_counts\n",
    "df2['pflength_duration'] = max_consecutive_durations\n",
    "# df2['azimuth'] = azimuths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e0923-2d0b-43c1-9632-41a7ec42c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get isolated and mcs/synoptic classifications\n",
    "iso_flags = []\n",
    "mcs_flags = []\n",
    "\n",
    "for event in events:\n",
    "    event_df = df2[df2.event == event]\n",
    "    \n",
    "    if event_df.max_pflength.to_list()[0] < iso_length:\n",
    "        iso_flags.append(1)\n",
    "    else:\n",
    "        iso_flags.append(0)\n",
    "    \n",
    "    if event_df.pflength_duration.to_list()[0] >= mcs_time:\n",
    "        mcs_flags.append(1)\n",
    "    else:\n",
    "        mcs_flags.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cad1d2-b391-4023-89fa-1e8e3afac245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769696cd-9d26-4af0-860b-d8b49f55a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flags to dataframe\n",
    "df_flagged = df2.copy()\n",
    "df_flagged['tc_flag'] = tc_flags\n",
    "df_flagged['iso_flag'] = iso_flags\n",
    "df_flagged['mcs_flag'] = mcs_flags\n",
    "df_flagged['noct_flag'] = noct_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536b967b-f2b5-44e4-b7de-c0c9b31125a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit iso/mcs flags so tc events do not conflict\n",
    "iso_flags2 = []\n",
    "mcs_flags2 = []\n",
    "\n",
    "for event in events:\n",
    "    event_df = df_flagged[df_flagged.event == event]\n",
    "    \n",
    "    if (event_df.iso_flag.to_list()[0]==1) & (event_df.tc_flag.to_list()[0]==0):\n",
    "        iso_flags2.append(1)\n",
    "    else:\n",
    "        iso_flags2.append(0)\n",
    "        \n",
    "    if (event_df.mcs_flag.to_list()[0]==1) & (event_df.tc_flag.to_list()[0]==0):\n",
    "        mcs_flags2.append(1)\n",
    "    else:\n",
    "        mcs_flags2.append(0)\n",
    "        \n",
    "df_flagged['iso_flag'] = iso_flags2\n",
    "df_flagged['mcs_flag'] = mcs_flags2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64535a98-1756-4321-ab7c-63480e964ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a8459-dda7-4600-99b8-584e896f7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move qc flags to the end\n",
    "column = df_flagged.pop('qc_flag')\n",
    "df_flagged['qc_flag'] = column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60701f83-8540-4973-95c0-142166b472a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882d5fb-9aac-4680-9c87-35a2dc0c5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data with qc flags\n",
    "df_flagged.to_csv(datadir+outputfname,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
